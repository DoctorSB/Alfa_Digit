{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Baseline\n",
    "\n",
    "В качестве бейзлайна используется модель NER, состоящая из RNN поверх эмбеддингов FastText (для получения эмбеддингов нужно запустить ноутбук `train_fasttext.ipynb`)\n",
    "\n",
    "Нормализация брендов и товаров не производится\n",
    "\n",
    "Бейзлайн реализован на библиотеке PyTorch с использованием PyTorch-Lightning для упрощения кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e740225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.745439800Z",
     "start_time": "2023-06-08T10:54:49.267906Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from rd import ReceiptsDataset\n",
    "import tensorboard\n",
    "import tensorboardX\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6be248c7",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "Полезные функции для работы с BIO-тегами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a45c869f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.749953400Z",
     "start_time": "2023-06-08T10:54:51.748949Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_bio_tagging(row):\n",
    "    \"\"\"\n",
    "    По токенам чека и разметке (то есть выделенным товарам и брендам) строим BIO-теги\n",
    "    \"\"\"\n",
    "    tokens = row[\"tokens\"]\n",
    "    good = row[\"good\"].split(',')[0].split()\n",
    "    brand = row[\"brand\"].split(',')[0].split()\n",
    "    tags = ['O'] * len(tokens)\n",
    "    for i, token in enumerate(tokens):\n",
    "        if len(good) > 0 and tokens[i:i + len(good)] == good:\n",
    "            tags[i] = \"B-GOOD\"\n",
    "            for j in range(i + 1, i + len(good)):\n",
    "                tags[j] = \"I-GOOD\"\n",
    "        if len(brand) > 0 and tokens[i:i + len(brand)] == brand:\n",
    "            tags[i] = \"B-BRAND\"\n",
    "            for j in range(i + 1, i + len(brand)):\n",
    "                tags[j] = \"I-BRAND\"\n",
    "    return tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c1ec439",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Прямое и обратное преобразование тегов в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b873cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.763150200Z",
     "start_time": "2023-06-08T10:54:51.752090200Z"
    }
   },
   "outputs": [],
   "source": [
    "index_to_tag = [\"O\", \"B-GOOD\", \"I-GOOD\", \"B-BRAND\", \"I-BRAND\", \"PAD\"]\n",
    "tag_to_index = {tag: index for index, tag in enumerate(index_to_tag)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "053a8c3d",
   "metadata": {},
   "source": [
    "# Datamodule\n",
    "\n",
    "Подготовим данные для модели. Для этого определим наследника `torch.nn.utils.Dataset` - `ReceiptsDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58c5aaec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.770658400Z",
     "start_time": "2023-06-08T10:54:51.763150200Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsDataset(Dataset):\n",
    "    def __init__(self, df, fasttext):\n",
    "        super().__init__()\n",
    "        self.is_predict = \"tags\" not in df.columns\n",
    "        self.data = df[[\"tokens\", \"good\", \"brand\", \"tags\"]] if not self.is_predict else df[[\"tokens\", \"id\"]]\n",
    "        self.data = self.data.values\n",
    "        self.fasttext = fasttext\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        identifier = 0 if not self.is_predict else self.data[index][1]\n",
    "        tokens = self.data[index][0]\n",
    "        embeddings = self.fasttext.wv[tokens]\n",
    "        goods = self.data[index][1].split(',') if not self.is_predict else list()\n",
    "        brands = self.data[index][2].split(',') if not self.is_predict else list()\n",
    "        tags = self.data[index][3] if not self.is_predict else [\"O\"] * len(tokens)\n",
    "        target = [tag_to_index[tag] for tag in tags]\n",
    "        return identifier, tokens, embeddings, goods, brands, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb96ba12",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Для объединения примеров в батчи нужна специальная `collate_fn`, в которой происходит паддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "847269bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.785171100Z",
     "start_time": "2023-06-08T10:54:51.772659Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    ids, tokens_sequence, embeddings_sequence, goods, brands, targets = list(zip(*batch))\n",
    "    embeddings_sequence = pad_sequence([torch.FloatTensor(sequence) for sequence in embeddings_sequence],\n",
    "                                       batch_first=True)\n",
    "    targets = pad_sequence([torch.LongTensor(target) for target in targets], batch_first=True,\n",
    "                           padding_value=tag_to_index[\"PAD\"])\n",
    "    return ids, tokens_sequence, embeddings_sequence, goods, brands, targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0db444bd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Используем LightningDataModule для задания пайплайна\n",
    "\n",
    "1. prepare_data\n",
    "    1. Токенизируем текст\n",
    "    2. Выделяем BIO-теги в размеченной части\n",
    "2. setup\n",
    "    1. Разделяем размеченную выборку на обучающую и валидационную\n",
    "    2. Создаем `ReceiptsDataset` под каждую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6ab59e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.792214800Z",
     "start_time": "2023-06-08T10:54:51.784173Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 train_dataset_path,\n",
    "                 test_dataset_path,\n",
    "                 fasttext_path,\n",
    "                 val_split_size,\n",
    "                 batch_size,\n",
    "                 num_workers):\n",
    "        super().__init__()\n",
    "        self.train_dataset_path = train_dataset_path\n",
    "        self.test_dataset_path = test_dataset_path\n",
    "        self.fasttext_path = fasttext_path\n",
    "        self.val_split_size = val_split_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.fasttext = FastText.load(self.fasttext_path)\n",
    "        self.train_df = pd.read_csv(self.train_dataset_path).fillna(\"\")\n",
    "        self.test_df = pd.read_csv(self.test_dataset_path)\n",
    "\n",
    "        self.train_df[\"tokens\"] = self.train_df[\"name\"].str.lower().str.split()\n",
    "        self.test_df[\"tokens\"] = self.test_df[\"name\"].str.lower().str.split()\n",
    "\n",
    "        self.train_df[\"tags\"] = self.train_df.apply(apply_bio_tagging, axis=1)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.train_df, self.val_df = train_test_split(self.train_df, test_size=self.val_split_size)\n",
    "\n",
    "        self.train_dataset = ReceiptsDataset(self.train_df, self.fasttext)\n",
    "        self.val_dataset = ReceiptsDataset(self.val_df, self.fasttext)\n",
    "        self.predict_dataset = ReceiptsDataset(self.test_df, self.fasttext)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c3aac1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.804924800Z",
     "start_time": "2023-06-08T10:54:51.794242200Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = \"data/train_supervised_dataset.csv\"\n",
    "TEST_DATASET_PATH = \"data/test_dataset.csv\"\n",
    "FASTTEXT_PATH = \"fasttext.model\"\n",
    "VAL_SPLIT_SIZE = 0.1\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c641742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.814434200Z",
     "start_time": "2023-06-08T10:54:51.805924300Z"
    }
   },
   "outputs": [],
   "source": [
    "dm = ReceiptsDataModule(\n",
    "    TRAIN_DATASET_PATH,\n",
    "    TEST_DATASET_PATH,\n",
    "    FASTTEXT_PATH,\n",
    "    VAL_SPLIT_SIZE,\n",
    "    BATCH_SIZE,\n",
    "    NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09717716",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Сначала определим метрику `F1` для задачи NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7db73afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.827296700Z",
     "start_time": "2023-06-08T10:54:51.814434200Z"
    }
   },
   "outputs": [],
   "source": [
    "class F1Score:\n",
    "    def __init__(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def update(self, pred, target):\n",
    "        pred = frozenset(x for x in pred)\n",
    "        target = frozenset(x for x in target)\n",
    "        self.tp += len(pred & target)\n",
    "        self.fp += len(pred - target)\n",
    "        self.fn += len(target - pred)\n",
    "\n",
    "    def reset(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def get(self):\n",
    "        if self.tp == 0:\n",
    "            return 0.0\n",
    "        precision = self.tp / (self.tp + self.fp)\n",
    "        recall = self.tp / (self.tp + self.fn)\n",
    "        return 2 / (1 / precision + 1 / recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "744cb027",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Зададим саму модель, ее шаги на обучении, валидации и инференсе, а также способ обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "469a277a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.841898200Z",
     "start_time": "2023-06-08T10:54:51.832413Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsModule(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 rnn_input_size,\n",
    "                 rnn_hidden_size,\n",
    "                 rnn_num_layers,\n",
    "                 rnn_dropout,\n",
    "                 mlp_hidden_size,\n",
    "                 learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lstm = nn.RNN(input_size=rnn_input_size,\n",
    "                           hidden_size=rnn_hidden_size,\n",
    "                           num_layers=rnn_num_layers,\n",
    "                           batch_first=True,\n",
    "                           dropout=rnn_dropout)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size, mlp_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_size, len(index_to_tag))\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=tag_to_index[\"PAD\"], reduction=\"mean\")\n",
    "        self.f1_good_train = F1Score()\n",
    "        self.f1_brand_train = F1Score()\n",
    "        self.f1_good_val = F1Score()\n",
    "        self.f1_brand_val = F1Score()\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        sequences, _ = self.lstm(sequences)\n",
    "        logits = self.mlp(sequences)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, goods, brands, targets = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        loss = self.criterion(logits.transpose(1, 2), targets)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"]\n",
    "            brands_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"]\n",
    "            self.f1_good_train.update(goods_pred, goods[i])\n",
    "            self.f1_brand_train.update(brands_pred, brands[i])\n",
    "        self.log(\"loss/train\", loss, on_epoch=True, batch_size=len(tags_indices_sequence))\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"metric/f1_good_train\", self.f1_good_train.get())\n",
    "        self.log(\"metric/f1_brand_train\", self.f1_brand_train.get())\n",
    "        self.f1_good_train.reset()\n",
    "        self.f1_brand_train.reset()\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, goods, brands, targets = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        loss = self.criterion(logits.transpose(1, 2), targets)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"]\n",
    "            brands_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"]\n",
    "            self.f1_good_val.update(goods_pred, goods[i])\n",
    "            self.f1_brand_val.update(brands_pred, brands[i])\n",
    "        self.log(\"loss/val\", loss, batch_size=len(tags_indices_sequence))\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"metric/f1_good_val\", self.f1_good_val.get())\n",
    "        self.log(\"metric/f1_brand_val\", self.f1_brand_val.get())\n",
    "        self.f1_good_val.reset()\n",
    "        self.f1_brand_val.reset()\n",
    "\n",
    "    def predict_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, _, _, _ = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        result = list()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = ','.join([' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"])\n",
    "            brands_pred = ','.join([' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"])\n",
    "            result.append([ids[i], goods_pred, brands_pred])\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c6e6593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.855590100Z",
     "start_time": "2023-06-08T10:54:51.838893600Z"
    }
   },
   "outputs": [],
   "source": [
    "RNN_INPUT_SIZE = 300\n",
    "RNN_HIDDEN_SIZE = 300\n",
    "RNN_NUM_LAYERS = 3\n",
    "RNN_DROPOUT = 0.1\n",
    "MLP_HIDDEN_SIZE = 500\n",
    "LEARNING_RATE = 1e-4\n",
    "model = ReceiptsModule(\n",
    "    RNN_INPUT_SIZE,\n",
    "    RNN_HIDDEN_SIZE,\n",
    "    RNN_NUM_LAYERS,\n",
    "    RNN_DROPOUT,\n",
    "    MLP_HIDDEN_SIZE,\n",
    "    LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87bbedf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.960372Z",
     "start_time": "2023-06-08T10:54:51.856590400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    # logger=False,\n",
    "    # max_epochs=30,\n",
    "    # log_every_n_steps=1\n",
    "\n",
    "    devices=[0],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"ner_rnn_baseline\"),\n",
    "    max_epochs=30,\n",
    "    log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "855166b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:08.087368500Z",
     "start_time": "2023-06-08T10:54:52.005941600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | lstm      | RNN              | 541 K \n",
      "1 | mlp       | Sequential       | 153 K \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "695 K     Trainable params\n",
      "0         Non-trainable params\n",
      "695 K     Total params\n",
      "2.781     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5bae880ac3465ea185ef40681dd5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 120, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 130, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ReceiptsDataset' on <module '__main__' (built-in)>\n",
      "/opt/homebrew/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Получение итоговых сущностей для тестового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2a974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.252851200Z",
     "start_time": "2023-06-08T10:57:08.087368500Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = trainer.predict(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e3b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.267357500Z",
     "start_time": "2023-06-08T10:57:13.254926100Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(sum(pred, list()), columns=[\"id\", \"good\", \"brand\"])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054b57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.277342Z",
     "start_time": "2023-06-08T10:57:13.270233600Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_baseline.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

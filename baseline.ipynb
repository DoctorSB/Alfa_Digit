{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline\n",
    "\n",
    "В качестве бейзлайна используется модель NER, состоящая из RNN поверх эмбеддингов FastText (для получения эмбеддингов нужно запустить ноутбук `train_fasttext.ipynb`)\n",
    "\n",
    "Нормализация брендов и товаров не производится\n",
    "\n",
    "Бейзлайн реализован на библиотеке PyTorch с использованием PyTorch-Lightning для упрощения кода"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e740225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.745439800Z",
     "start_time": "2023-06-08T10:54:49.267906Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be248c7",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "Полезные функции для работы с BIO-тегами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45c869f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.749953400Z",
     "start_time": "2023-06-08T10:54:51.748949Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_bio_tagging(row):\n",
    "    \"\"\"\n",
    "    По токенам чека и разметке (то есть выделенным товарам и брендам) строим BIO-теги\n",
    "    \"\"\"\n",
    "    tokens = row[\"tokens\"]\n",
    "    good = row[\"good\"].split(',')[0].split()\n",
    "    brand = row[\"brand\"].split(',')[0].split()\n",
    "    tags = ['O'] * len(tokens)\n",
    "    for i, token in enumerate(tokens):\n",
    "        if len(good) > 0 and tokens[i:i + len(good)] == good:\n",
    "            tags[i] = \"B-GOOD\"\n",
    "            for j in range(i + 1, i + len(good)):\n",
    "                tags[j] = \"I-GOOD\"\n",
    "        if len(brand) > 0 and tokens[i:i + len(brand)] == brand:\n",
    "            tags[i] = \"B-BRAND\"\n",
    "            for j in range(i + 1, i + len(brand)):\n",
    "                tags[j] = \"I-BRAND\"\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Прямое и обратное преобразование тегов в индексы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b873cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.763150200Z",
     "start_time": "2023-06-08T10:54:51.752090200Z"
    }
   },
   "outputs": [],
   "source": [
    "index_to_tag = [\"O\", \"B-GOOD\", \"I-GOOD\", \"B-BRAND\", \"I-BRAND\", \"PAD\"]\n",
    "tag_to_index = {tag: index for index, tag in enumerate(index_to_tag)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a8c3d",
   "metadata": {},
   "source": [
    "# Datamodule\n",
    "\n",
    "Подготовим данные для модели. Для этого определим наследника `torch.nn.utils.Dataset` - `ReceiptsDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c5aaec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.770658400Z",
     "start_time": "2023-06-08T10:54:51.763150200Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsDataset(Dataset):\n",
    "    def __init__(self, df, fasttext):\n",
    "        super().__init__()\n",
    "        self.is_predict = \"tags\" not in df.columns\n",
    "        self.data = df[[\"tokens\", \"good\", \"brand\", \"tags\"]] if not self.is_predict else df[[\"tokens\", \"id\"]]\n",
    "        self.data = self.data.values\n",
    "        self.fasttext = fasttext\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        identifier = 0 if not self.is_predict else self.data[index][1]\n",
    "        tokens = self.data[index][0]\n",
    "        embeddings = self.fasttext.wv[tokens]\n",
    "        goods = self.data[index][1].split(',') if not self.is_predict else list()\n",
    "        brands = self.data[index][2].split(',') if not self.is_predict else list()\n",
    "        tags = self.data[index][3] if not self.is_predict else [\"O\"] * len(tokens)\n",
    "        target = [tag_to_index[tag] for tag in tags]\n",
    "        return identifier, tokens, embeddings, goods, brands, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для объединения примеров в батчи нужна специальная `collate_fn`, в которой происходит паддинг"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847269bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.785171100Z",
     "start_time": "2023-06-08T10:54:51.772659Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    ids, tokens_sequence, embeddings_sequence, goods, brands, targets = list(zip(*batch))\n",
    "    embeddings_sequence = pad_sequence([torch.FloatTensor(sequence) for sequence in embeddings_sequence],\n",
    "                                       batch_first=True)\n",
    "    targets = pad_sequence([torch.LongTensor(target) for target in targets], batch_first=True,\n",
    "                           padding_value=tag_to_index[\"PAD\"])\n",
    "    return ids, tokens_sequence, embeddings_sequence, goods, brands, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Используем LightningDataModule для задания пайплайна\n",
    "\n",
    "1. prepare_data\n",
    "    1. Токенизируем текст\n",
    "    2. Выделяем BIO-теги в размеченной части\n",
    "2. setup\n",
    "    1. Разделяем размеченную выборку на обучающую и валидационную\n",
    "    2. Создаем `ReceiptsDataset` под каждую выборку"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6ab59e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.792214800Z",
     "start_time": "2023-06-08T10:54:51.784173Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 train_dataset_path,\n",
    "                 test_dataset_path,\n",
    "                 fasttext_path,\n",
    "                 val_split_size,\n",
    "                 batch_size,\n",
    "                 num_workers):\n",
    "        super().__init__()\n",
    "        self.train_dataset_path = train_dataset_path\n",
    "        self.test_dataset_path = test_dataset_path\n",
    "        self.fasttext_path = fasttext_path\n",
    "        self.val_split_size = val_split_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.fasttext = FastText.load(self.fasttext_path)\n",
    "        self.train_df = pd.read_csv(self.train_dataset_path).fillna(\"\")\n",
    "        self.test_df = pd.read_csv(self.test_dataset_path)\n",
    "\n",
    "        self.train_df[\"tokens\"] = self.train_df[\"name\"].str.lower().str.split()\n",
    "        self.test_df[\"tokens\"] = self.test_df[\"name\"].str.lower().str.split()\n",
    "\n",
    "        self.train_df[\"tags\"] = self.train_df.apply(apply_bio_tagging, axis=1)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.train_df, self.val_df = train_test_split(self.train_df, test_size=self.val_split_size)\n",
    "\n",
    "        self.train_dataset = ReceiptsDataset(self.train_df, self.fasttext)\n",
    "        self.val_dataset = ReceiptsDataset(self.val_df, self.fasttext)\n",
    "        self.predict_dataset = ReceiptsDataset(self.test_df, self.fasttext)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c3aac1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.804924800Z",
     "start_time": "2023-06-08T10:54:51.794242200Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = \"train_supervised_dataset.csv\"\n",
    "TEST_DATASET_PATH = \"test_dataset.csv\"\n",
    "FASTTEXT_PATH = \"fasttext.model\"\n",
    "VAL_SPLIT_SIZE = 0.1\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c641742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.814434200Z",
     "start_time": "2023-06-08T10:54:51.805924300Z"
    }
   },
   "outputs": [],
   "source": [
    "dm = ReceiptsDataModule(\n",
    "    TRAIN_DATASET_PATH,\n",
    "    TEST_DATASET_PATH,\n",
    "    FASTTEXT_PATH,\n",
    "    VAL_SPLIT_SIZE,\n",
    "    BATCH_SIZE,\n",
    "    NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09717716",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Сначала определим метрику `F1` для задачи NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db73afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.827296700Z",
     "start_time": "2023-06-08T10:54:51.814434200Z"
    }
   },
   "outputs": [],
   "source": [
    "class F1Score:\n",
    "    def __init__(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def update(self, pred, target):\n",
    "        pred = frozenset(x for x in pred)\n",
    "        target = frozenset(x for x in target)\n",
    "        self.tp += len(pred & target)\n",
    "        self.fp += len(pred - target)\n",
    "        self.fn += len(target - pred)\n",
    "\n",
    "    def reset(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def get(self):\n",
    "        if self.tp == 0:\n",
    "            return 0.0\n",
    "        precision = self.tp / (self.tp + self.fp)\n",
    "        recall = self.tp / (self.tp + self.fn)\n",
    "        return 2 / (1 / precision + 1 / recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Зададим саму модель, ее шаги на обучении, валидации и инференсе, а также способ обучения"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469a277a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.841898200Z",
     "start_time": "2023-06-08T10:54:51.832413Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReceiptsModule(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 rnn_input_size,\n",
    "                 rnn_hidden_size,\n",
    "                 rnn_num_layers,\n",
    "                 rnn_dropout,\n",
    "                 mlp_hidden_size,\n",
    "                 learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lstm = nn.RNN(input_size=rnn_input_size,\n",
    "                           hidden_size=rnn_hidden_size,\n",
    "                           num_layers=rnn_num_layers,\n",
    "                           batch_first=True,\n",
    "                           dropout=rnn_dropout)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size, mlp_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_size, len(index_to_tag))\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=tag_to_index[\"PAD\"], reduction=\"mean\")\n",
    "        self.f1_good_train = F1Score()\n",
    "        self.f1_brand_train = F1Score()\n",
    "        self.f1_good_val = F1Score()\n",
    "        self.f1_brand_val = F1Score()\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        sequences, _ = self.lstm(sequences)\n",
    "        logits = self.mlp(sequences)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, goods, brands, targets = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        loss = self.criterion(logits.transpose(1, 2), targets)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"]\n",
    "            brands_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"]\n",
    "            self.f1_good_train.update(goods_pred, goods[i])\n",
    "            self.f1_brand_train.update(brands_pred, brands[i])\n",
    "        self.log(\"loss/train\", loss, on_epoch=True, batch_size=len(tags_indices_sequence))\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"metric/f1_good_train\", self.f1_good_train.get())\n",
    "        self.log(\"metric/f1_brand_train\", self.f1_brand_train.get())\n",
    "        self.f1_good_train.reset()\n",
    "        self.f1_brand_train.reset()\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, goods, brands, targets = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        loss = self.criterion(logits.transpose(1, 2), targets)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"]\n",
    "            brands_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"]\n",
    "            self.f1_good_val.update(goods_pred, goods[i])\n",
    "            self.f1_brand_val.update(brands_pred, brands[i])\n",
    "        self.log(\"loss/val\", loss, batch_size=len(tags_indices_sequence))\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"metric/f1_good_val\", self.f1_good_val.get())\n",
    "        self.log(\"metric/f1_brand_val\", self.f1_brand_val.get())\n",
    "        self.f1_good_val.reset()\n",
    "        self.f1_brand_val.reset()\n",
    "\n",
    "    def predict_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, _, _, _ = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        result = list()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = ','.join([' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"])\n",
    "            brands_pred = ','.join([' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"])\n",
    "            result.append([ids[i], goods_pred, brands_pred])\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6e6593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.855590100Z",
     "start_time": "2023-06-08T10:54:51.838893600Z"
    }
   },
   "outputs": [],
   "source": [
    "RNN_INPUT_SIZE = 300\n",
    "RNN_HIDDEN_SIZE = 300\n",
    "RNN_NUM_LAYERS = 3\n",
    "RNN_DROPOUT = 0.1\n",
    "MLP_HIDDEN_SIZE = 500\n",
    "LEARNING_RATE = 1e-4\n",
    "model = ReceiptsModule(\n",
    "    RNN_INPUT_SIZE,\n",
    "    RNN_HIDDEN_SIZE,\n",
    "    RNN_NUM_LAYERS,\n",
    "    RNN_DROPOUT,\n",
    "    MLP_HIDDEN_SIZE,\n",
    "    LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87bbedf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:54:51.960372Z",
     "start_time": "2023-06-08T10:54:51.856590400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"ner_rnn_baseline\"),\n",
    "    max_epochs=30,\n",
    "    log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "855166b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:08.087368500Z",
     "start_time": "2023-06-08T10:54:52.005941600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: tb_logs/ner_rnn_baseline\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | lstm      | RNN              | 541 K \n",
      "1 | mlp       | Sequential       | 153 K \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "695 K     Trainable params\n",
      "0         Non-trainable params\n",
      "695 K     Total params\n",
      "2.781     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f396d09420274dfc8480f359757ee4cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8750ce5690c40ffb1ab48a14b3d94b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xterrafunny/anaconda3/envs/nlp_in_practice_receipts/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21a43b81f9334de3b38203cc141bddbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "831ae1098d4044419480bd609cbc7c68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c31385d6b254b259ceb8553a6dbea85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed0ceddfed5242d283cb890d7b113b6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d637de19d604aeaa3208300061bb266"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f95f60554a24fbe9d83750c4b53cf9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1190907087404b769ed549a10ab6d18a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa3d561f1f7f40199447f2e957627cbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7822b81bde2472fad80ed2f5bdfb4de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b27eb48ab804187ad071983df2cccf0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "714cc4804c7143ff9782adf26989c2b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9740a82e04a04782be2bf9ecf3b97f73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3720fb2269024156a50cce0fb9ef17a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "828b3c7c0c38427988e839356fabde41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47a51e525b6b40808f9e295ddcb3a9e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e8398e1024f415bad36af749d500e31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0f24c03617e4bd5a5f9800f593866e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d62dad044f64e0bb5c4973f82a835aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9af10d815e614206af34f9c7fdfa2f09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba5066ff3d534eeb9510497fb6d2c685"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff58731ac6924c3f9d987e917f98908f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd9e838030544bb9b308bf43ab0dd35b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5a4b51c90ab4082b8fe1ad7632aeb6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cb9723f17ca4319a9ea02a1344f14e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58ed82b96e6e4ca383d520ea0cd9edf2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea5952294a65424cbde51b736bf79b29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64f4b2a7125d41ca8dc29ea39a02c0dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14a0f8d2ad264690a1fccd8b594f316b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "634fd117fe904aa1a996c86e80aaf04f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32f5de8f3fbc4ca6a3aa56ad8fe6bd19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получение итоговых сущностей для тестового датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ac2a974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.252851200Z",
     "start_time": "2023-06-08T10:57:08.087368500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "099cb9d4ecb0435d9a8634e2d4e6fcd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f54e3b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.267357500Z",
     "start_time": "2023-06-08T10:57:13.254926100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        id         good brand\n0        0                   \n1        1         торт      \n2        2    смеситель      \n3        3        лимон      \n4        4       коньяк      \n...    ...          ...   ...\n4995  4995        рамка      \n4996  4996                   \n4997  4997  наконечники      \n4998  4998      шоколад      \n4999  4999        опора      \n\n[5000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>good</th>\n      <th>brand</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>торт</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>смеситель</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>лимон</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>коньяк</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>4995</td>\n      <td>рамка</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>4996</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>4997</td>\n      <td>наконечники</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>4998</td>\n      <td>шоколад</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>4999</td>\n      <td>опора</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(sum(pred, list()), columns=[\"id\", \"good\", \"brand\"])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d054b57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T10:57:13.277342Z",
     "start_time": "2023-06-08T10:57:13.270233600Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_baseline.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
